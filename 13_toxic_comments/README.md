# Toxic Comments

## Описание проекта
Классификатор токсичных комментариев для сервиса «Викишоп»: предобработка текста, TF‑IDF и обучение моделей машинного обучения.

## Цель
Автоматизировать модерацию пользовательских правок, достигая F1 ≥ 0.75 на тестовой выборке.

## Стек технологий
`Python`, `Pandas`, `NumPy`, `scikit-learn`, `NLTK`, `CatBoost`

## Функциональность
- Очистка текста: лемматизация, удаление стоп-слов, регулярные выражения.
- Построение TF-IDF-признаков и эксперименты с Logistic Regression, CatBoost и бейзлайнами.
- Кросс-валидация, подбор гиперпараметров и оценка метрик (F1, accuracy).
- Подготовка рекомендаций по интеграции модели в модерацию.

## Инструкция по запуску
1. Установите зависимости: `pip install -r requirements.txt`.
2. Скачайте `toxic_comments.csv` и поместите рядом с `toxic_comments.ipynb`.
3. Запустите ноутбук в Jupyter и выполните ячейки последовательно.
