# Toxic Comments

**Цель:** Классифицировать токсичные комментарии для модерации пользовательских правок в «Викишопе».  
**Данные:** `toxic_comments.csv` — тексты комментариев и бинарная разметка токсичности.  
**Подход:** Предобработка текста, TF-IDF-признаки, обучение LogisticRegression и альтернативных моделей с кросс-валидацией.  
**Метрики/результаты:** LogisticRegression достигла F1 ≈ 0.77 на тесте, превысив целевой порог 0.75 и опередив DummyClassifier.

## Стек
`Python`, `Pandas`, `NumPy`, `scikit-learn`, `NLTK`, `CatBoost`

## Файлы
- `toxic_comments.ipynb` — подготовка текстовых признаков и обучение классификаторов.

## Быстрый старт
- Установите зависимости: `pip install -r requirements.txt`.
- Загрузите `toxic_comments.csv` и выполните ноутбук в Jupyter.
